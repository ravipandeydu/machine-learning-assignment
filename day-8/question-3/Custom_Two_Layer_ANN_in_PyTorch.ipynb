{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# main_script.py\n",
        "\n",
        "# --- 1. Import necessary libraries ---\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# --- 2. Data Generation and Loading ---\n",
        "# This section uses the same function as before to ensure the same dataset is used.\n",
        "\n",
        "def generate_or_load_data(filename='binary_data.csv'):\n",
        "    \"\"\"\n",
        "    Generates a synthetic binary classification dataset if the file doesn't exist.\n",
        "    Loads the data from the CSV file into a pandas DataFrame.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"'{filename}' not found. Generating a new dataset.\")\n",
        "        # Generate a dataset with 100 samples, 2 input features, and 2 classes.\n",
        "        X, y = make_classification(\n",
        "            n_samples=100,\n",
        "            n_features=2,\n",
        "            n_informative=2,\n",
        "            n_redundant=0,\n",
        "            n_classes=2,\n",
        "            random_state=1\n",
        "        )\n",
        "        # Create a DataFrame and save it to CSV.\n",
        "        df = pd.DataFrame(X, columns=['feature_1', 'feature_2'])\n",
        "        df['label'] = y\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Dataset saved to '{filename}'.\")\n",
        "    else:\n",
        "        print(f\"Loading existing dataset from '{filename}'.\")\n",
        "\n",
        "    # Load the data from the CSV file.\n",
        "    return pd.read_csv(filename)\n",
        "\n",
        "# --- 3. Activation and Loss Functions (Manual Implementation) ---\n",
        "# We use built-in torch.relu, but define sigmoid and BCE loss manually.\n",
        "\n",
        "def sigmoid(z):\n",
        "    \"\"\"Sigmoid activation function for the output layer.\"\"\"\n",
        "    return 1 / (1 + torch.exp(-z))\n",
        "\n",
        "def binary_cross_entropy_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Binary Cross-Entropy loss function.\n",
        "    We add a small epsilon value to prevent log(0) which results in NaN.\n",
        "    \"\"\"\n",
        "    epsilon = 1e-7\n",
        "    # Clamp predictions to avoid log(0) or log(1) issues\n",
        "    y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
        "    # BCE formula\n",
        "    loss = -torch.mean(y_true * torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred))\n",
        "    return loss\n",
        "\n",
        "# --- 4. Main Execution Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Data Preparation ---\n",
        "    # Load data using the function defined above.\n",
        "    data_df = generate_or_load_data()\n",
        "    X = data_df[['feature_1', 'feature_2']].values\n",
        "    y = data_df['label'].values\n",
        "\n",
        "    # Split data into training (80%) and testing (20%) sets.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # --- Convert to PyTorch Tensors and Move to Device ---\n",
        "    # Set device to GPU if available, otherwise CPU.\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"\\nUsing device: '{device}'\")\n",
        "\n",
        "    # Convert numpy arrays to PyTorch tensors.\n",
        "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "    # --- Hyperparameters ---\n",
        "    n_input_features = X_train_tensor.shape[1] # Should be 2\n",
        "    n_hidden_units = 4\n",
        "    n_output_units = 1\n",
        "    learning_rate = 0.1\n",
        "    epochs = 100\n",
        "\n",
        "    # --- Model Initialization (Manual 2-4-1 Architecture) ---\n",
        "    # Layer 1: Input (2) to Hidden (4)\n",
        "    W1 = torch.randn(n_input_features, n_hidden_units, device=device, requires_grad=True, dtype=torch.float32)\n",
        "    b1 = torch.zeros(1, n_hidden_units, device=device, requires_grad=True, dtype=torch.float32)\n",
        "\n",
        "    # Layer 2: Hidden (4) to Output (1)\n",
        "    W2 = torch.randn(n_hidden_units, n_output_units, device=device, requires_grad=True, dtype=torch.float32)\n",
        "    b2 = torch.zeros(1, n_output_units, device=device, requires_grad=True, dtype=torch.float32)\n",
        "\n",
        "    print(\"\\n--- Starting Training for 2-4-1 ANN ---\")\n",
        "    # --- Training Loop ---\n",
        "    for epoch in range(epochs):\n",
        "        # --- Forward Pass ---\n",
        "        # 1. First linear layer (input to hidden)\n",
        "        Z1 = X_train_tensor @ W1 + b1\n",
        "        # 2. First activation (ReLU)\n",
        "        A1 = torch.relu(Z1)\n",
        "        # 3. Second linear layer (hidden to output)\n",
        "        Z2 = A1 @ W2 + b2\n",
        "        # 4. Final activation (Sigmoid for binary classification)\n",
        "        y_pred = sigmoid(Z2)\n",
        "\n",
        "        # --- Calculate Loss ---\n",
        "        loss = binary_cross_entropy_loss(y_train_tensor, y_pred)\n",
        "\n",
        "        # --- Backward Pass ---\n",
        "        # This single call computes gradients for all tensors with requires_grad=True\n",
        "        # (W1, b1, W2, b2) that were part of the loss computation.\n",
        "        loss.backward()\n",
        "\n",
        "        # --- Manual Weight Update (Gradient Descent) ---\n",
        "        # Use torch.no_grad() to ensure these updates are not tracked by autograd.\n",
        "        with torch.no_grad():\n",
        "            # Update weights and biases for both layers\n",
        "            W1 -= learning_rate * W1.grad\n",
        "            b1 -= learning_rate * b1.grad\n",
        "            W2 -= learning_rate * W2.grad\n",
        "            b2 -= learning_rate * b2.grad\n",
        "\n",
        "            # --- Zero the Gradients ---\n",
        "            # This is critical to prevent gradient accumulation across epochs.\n",
        "            W1.grad.zero_()\n",
        "            b1.grad.zero_()\n",
        "            W2.grad.zero_()\n",
        "            b2.grad.zero_()\n",
        "\n",
        "        # Print loss every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    print(\"--- Training Finished ---\\n\")\n",
        "\n",
        "    # --- Evaluation on Test Set ---\n",
        "    with torch.no_grad():\n",
        "        # Perform a forward pass with the trained weights on the test data\n",
        "        Z1_test = X_test_tensor @ W1 + b1\n",
        "        A1_test = torch.relu(Z1_test)\n",
        "        Z2_test = A1_test @ W2 + b2\n",
        "        test_pred_probs = sigmoid(Z2_test)\n",
        "\n",
        "        # Convert probabilities to binary predictions (0 or 1)\n",
        "        test_pred_labels = (test_pred_probs >= 0.5).float()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = (test_pred_labels == y_test_tensor).sum().item() / len(y_test_tensor)\n",
        "        print(f\"Accuracy on test set: {accuracy * 100:.2f}%\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'binary_data.csv' not found. Generating a new dataset.\n",
            "Dataset saved to 'binary_data.csv'.\n",
            "\n",
            "Using device: 'cpu'\n",
            "\n",
            "--- Starting Training for 2-4-1 ANN ---\n",
            "Epoch 10/100, Loss: 0.4951\n",
            "Epoch 20/100, Loss: 0.3661\n",
            "Epoch 30/100, Loss: 0.2967\n",
            "Epoch 40/100, Loss: 0.2522\n",
            "Epoch 50/100, Loss: 0.2183\n",
            "Epoch 60/100, Loss: 0.1934\n",
            "Epoch 70/100, Loss: 0.1733\n",
            "Epoch 80/100, Loss: 0.1568\n",
            "Epoch 90/100, Loss: 0.1434\n",
            "Epoch 100/100, Loss: 0.1322\n",
            "--- Training Finished ---\n",
            "\n",
            "Accuracy on test set: 100.00%\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01Uzuq_nOJPd",
        "outputId": "0aa6a895-b683-4bd5-92b0-d8935917e56c"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}